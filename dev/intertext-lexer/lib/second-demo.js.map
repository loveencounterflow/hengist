{
  "version": 3,
  "file": "",
  "sourceRoot": "",
  "sources": [
    "../src/second-demo.coffee"
  ],
  "names": [],
  "mappings": "AACA;EAAA;AAAA,MAAA,GAAA,EAAA,CAAA,EAAA,QAAA,EAAA,KAAA,EAAA,MAAA,EAAA,KAAA,EAAA,OAAA,EAAA,OAAA,EAAA,OAAA,EAAA,UAAA,EAAA,KAAA,EAAA,YAAA,EAAA,4BAAA,EAAA,eAAA,EAAA,MAAA,EAAA,MAAA,EAAA,IAAA,EAAA,MAAA,EAAA,MAAA,EAAA,KAAA,EAAA,IAAA,EAAA,IAAA,EAAA,OAAA,EAAA,GAAA,EAAA,SAAA,EAAA,UAAA,EAAA,KAAA,EAAA,YAAA,EAAA,OAAA,EAAA,QAAA,EAAA,SAAA,EAAA,KAAA,EAAA,MAAA,EAAA,GAAA,EAAA,GAAA,EAAA,QAAA,EAAA,MAAA,EAAA,MAAA,EAAA,QAAA,EAAA,KAAA,EAAA,OAAA,EAAA,IAAA,EAAA,IAAA,EAAA,OAAA;;;EAIA,GAAA,GAA4B,OAAA,CAAQ,KAAR;;EAC5B,CAAA,CAAE,KAAF,EACE,KADF,EAEE,IAFF,EAGE,IAHF,EAIE,KAJF,EAKE,MALF,EAME,IANF,EAOE,IAPF,EAQE,OARF,CAAA,GAQ4B,GAAG,CAAC,GAAG,CAAC,WAAR,CAAoB,qBAApB,CAR5B;;EASA,CAAA,CAAE,GAAF,EACE,OADF,EAEE,IAFF,EAGE,GAHF,CAAA,GAG4B,GAAG,CAAC,GAHhC;;EAIA,KAAA,GAA4B,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,IAAd,CAAmB,GAAG,CAAC,GAAvB,EAlB5B;;;EAoBA,CAAA,CAAE,MAAF,EACE,UADF,CAAA,GAC4B,GAAG,CAAC,QADhC;;EAEA,CAAA,CAAE,QAAF,CAAA,GAA4B,OAAA,CAAQ,UAAR,CAA5B,EAtBA;;;EAwBA,CAAA,GAA4B,OAAA,CAAQ,sBAAR;;EAC5B,CAAA,CAAE,QAAF,EACE,OADF,CAAA,GAC4B,OAAA,CAAQ,+BAAR,CAD5B;;EAEA,CAAA,CAAE,MAAF,EACE,KADF,EAEE,OAFF,EAGE,OAHF,EAIE,MAJF,EAKE,KALF,EAME,SANF,EAOE,UAPF,EAQE,KARF,EASE,YATF,EAUE,OAVF,EAWE,QAXF,EAYE,SAZF,EAaE,GAbF,EAcE,QAdF,EAeE,MAfF,CAAA,GAe4B,OAf5B,EA3BA;;;EA8CA,OAAA,GAAU,QAAA,CAAE,CAAF,CAAA;IAAS,IAAK,CAAA,YAAa,MAAlB;aAAgC,UAAA,CAAW,CAAX,EAAc;QAAE,OAAA,EAAS;MAAX,CAAd,EAAhC;KAAA,MAAA;aAAsE,KAAK,CAAC,GAAN,CAAU,GAAV,EAAe,CAAf,EAAtE;;EAAT;;EACV,MAAA,GAAU,QAAA,CAAE,CAAF,CAAA;IAAS,IAAK,CAAA,YAAa,MAAlB;aAAgC,UAAA,CAAW,CAAX,EAAc;QAAE,MAAA,EAAQ;MAAV,CAAd,EAAhC;KAAA,MAAA;aAAsE,KAAK,CAAC,GAAN,CAAU,GAAV,EAAe,CAAf,EAAtE;;EAAT;;EACV,MAAA,GAAU,QAAA,CAAE,CAAF,CAAA;IAAS,IAAK,CAAA,YAAa,MAAlB;aAAgC,UAAA,CAAW,CAAX,EAAc;QAAE,MAAA,EAAQ;MAAV,CAAd,EAAhC;KAAA,MAAA;aAAsE,KAAK,CAAC,GAAN,CAAU,GAAV,EAAe,CAAf,EAAtE;;EAAT;;EACV,MAAA,GAAU,OAjDV;;;EAoDA,YAAA,GAAe,QAAA,CAAA,CAAA;AACf,QAAA,CAAA,EAAA,GAAA,EAAA,CAAA,EAAA,GAAA,EAAA,IAAA,EAAA,KAAA,EAAA,KAAA,EAAA,MAAA,EAAA,KAAA,EAAA;IAAE,KAAA,GAAU,IAAI,QAAJ,CAAA;IAEP,CAAA,CAAA,CAAA,GAAA,EAAA;;AACL,UAAA;MACI,IAAA,GAAU;MACV,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,QAAb;QAAiC,OAAA,EAAW;MAA5C,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,MAAb;QAAiC,OAAA,EAAW,MAAA,CAAO,GAAP,EAAY,OAAO,CAAC,UAAR,CAAmB,UAAnB,CAAZ;MAA5C,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,KAAb;QAAoB,IAAA,EAAM,KAA1B;QAAiC,OAAA,EAAW;MAA5C,CAAjB;aACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,aAAb;QAAiC,OAAA,EAAW;MAA5C,CAAjB;IANC,CAAA;IASA,CAAA,CAAA,CAAA,GAAA,EAAA;;AACL,UAAA;MAAI,IAAA,GAAU;MACV,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,QAAb;QAA+B,OAAA,EAAW;MAA1C,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,KAAb;QAAoB,IAAA,EAAM,GAA1B;QAA+B,OAAA,EAAW;MAA1C,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,MAAb;QAA+B,OAAA,EAAW,MAAA,CAAO,GAAP,EAAY,OAAO,CAAC,UAAR,CAAmB,QAAnB,CAAZ;MAA1C,CAAjB;aACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,OAAb;QAA+B,OAAA,EAAW;MAA1C,CAAjB;IALC,CAAA,IAXL;;IAkBE,MAAA,GAAgB,CACd,2BADc,EAEd,gBAFc,EAGd,kBAHc,EAId,MAJc,EAKd,cALc,EAMd,KANc,EAOd,IAPc,EAQd,GARc,EASd,EATc,EAUd,6BAVc,EAWd,oCAXc,EAYd,gBAZc,EAlBlB;;IAiCE,KAAA,wCAAA;;MACE,OAAA,CAAQ,QAAR,EAAkB,0EAAlB;MACA,MAAA,GAAY,KAAK,CAAC,GAAN,CAAU,KAAV,EADhB;;MAGI,KAAA,sDAAA;;QACE,IAAgB,KAAK,CAAC,GAAN,KAAa,QAA7B;AAAA,mBAAA;;QACA,KAAK,CAAC,GAAN,GAAY,GAAG,CAAC,GAAG,CAAC,GAAR,CAAY,KAAK,CAAC,GAAlB;MAFd;MAGA,CAAC,CAAC,QAAF,CAAW,CAAA,UAAA,CAAA,CAAa,GAAA,CAAI,KAAJ,CAAb,CAAA,CAAX,EAAqC,MAArC;IAPF,CAjCF;;AA0CE,WAAO;EA3CM,EApDf;;;EAkGA,eAAA,GAAkB,QAAA,CAAA,CAAA;AAClB,QAAA,KAAA,EAAA,GAAA,EAAA,WAAA,EAAA,IAAA,EAAA;IAAE,KAAA,GAAU,IAAI,QAAJ,CAAa;MAAE,MAAA,EAAQ;IAAV,CAAb,EAAZ;;IAEE,IAAA,GAAc;IACd,WAAA,GAAc;IAWd,GAAA,GAAM,WAAW,CAAC;IAClB,KAAK,CAAC,UAAN,CAAiB;MAAE,IAAF;MAAQ,GAAA,EAAK,OAAb;MAAsB,OAAA,EAAW,OAAjC;IAAA,CAAjB;IACA,KAAK,CAAC,UAAN,CAAiB;MAAE,IAAF;MAAQ,GAAA,EAAK,KAAb;MAAsB,OAAA,EAAW,MAAA,CAAA,CAAA,GAAA,CAAA,CAAY,GAAZ;;;;CAAA,aAAA,CAAA,CAEY,GAFZ,CAAA,MAAA,CAAA,EAIa,GAJb;IAAjC,CAAjB;IAKA,KAAK,CAAC,UAAN,CAAiB;MAAE,IAAF;MAAQ,GAAA,EAAK,GAAb;MAAsB,OAAA,EAAS,MAAA,CAAA,CAAA,qBAAA,CAAA,CACa,GADb;;CAAA,OAAA,CAAA,EAEO,GAFP;IAA/B,CAAjB,EArBF;;IAyBE,KAAA,GAAQ,CAAA;;;;;;;;;;;;;;AAAA,EAzBV;;;;;IA8CE,IAAA,CAAK,QAAL,EAAe,GAAA,CAAI,KAAJ,CAAf,EA9CF;;;;;IAmDE,CAAC,CAAC,QAAF,CAAW,YAAX,EAAyB,KAAK,CAAC,GAAN,CAAU,KAAV,CAAzB,EAnDF;;AAqDE,WAAO;EAtDS,EAlGlB;;;EA4JA,4BAAA,GAA+B,QAAA,CAAA,CAAA,EAAA,EA5J/B;;;EAgKA,IAAG,MAAA,KAAU,OAAO,CAAC,IAArB;IAAkC,CAAA,CAAA,CAAA,GAAA,EAAA;;;;aAIhC,eAAA,CAAA;IAJgC,CAAA,IAAlC;;;EAhKA;;;;;;;;;;;;;AAAA",
  "sourcesContent": [
    "\n'use strict'\n\n\n############################################################################################################\nGUY                       = require 'guy'\n{ alert\n  debug\n  help\n  info\n  plain\n  praise\n  urge\n  warn\n  whisper }               = GUY.trm.get_loggers 'DEMO-COMPOSE-REGEXP'\n{ rpr\n  inspect\n  echo\n  log     }               = GUY.trm\ntruth                     = GUY.trm.truth.bind GUY.trm\n#...........................................................................................................\n{ equals\n  copy_regex }            = GUY.samesame\n{ to_width }              = require 'to-width'\n#...........................................................................................................\nH                         = require '../../../lib/helpers'\n{ Interlex\n  compose  }              = require '../../../apps/intertext-lexer'\n{ atomic\n  bound\n  capture\n  charSet\n  either\n  flags\n  lookAhead\n  lookBehind\n  maybe\n  namedCapture\n  noBound\n  notAhead\n  notBehind\n  ref\n  sequence\n  suffix                } = compose\n\n\n#-----------------------------------------------------------------------------------------------------------\nunicode = ( x ) -> if ( x instanceof RegExp ) then copy_regex x, { unicode: true, } else flags.add 'u', x\nsticky  = ( x ) -> if ( x instanceof RegExp ) then copy_regex x, { sticky: true,  } else flags.add 'y', x\ndotall  = ( x ) -> if ( x instanceof RegExp ) then copy_regex x, { dotAll: true,  } else flags.add 's', x\ndotAll  = dotall\n\n#-----------------------------------------------------------------------------------------------------------\ndemo_htmlish = ->\n  lexer   = new Interlex()\n  #.........................................................................................................\n  do =>\n    ### NOTE arbitrarily forbidding question marks and not using fallback token to test for error tokens ###\n    mode    = 'plain'\n    lexer.add_lexeme { mode, tid: 'escchr',           pattern: ( /\\\\(?<chr>.)/u                             ), }\n    lexer.add_lexeme { mode, tid: 'text',             pattern: ( suffix '+', charSet.complement /[<`\\\\?]/u  ), }\n    lexer.add_lexeme { mode, tid: 'tag', jump: 'tag', pattern: ( /<(?<lslash>\\/?)/u                         ), }\n    lexer.add_lexeme { mode, tid: 'E_backticks',      pattern: ( /`+/                                       ), }\n    # lexer.add_lexeme mode, 'other',        /./u\n  #.........................................................................................................\n  do =>\n    mode    = 'tag'\n    lexer.add_lexeme { mode, tid: 'escchr',         pattern: ( /\\\\(?<chr>.)/u                           ), }\n    lexer.add_lexeme { mode, tid: 'end', jump: '^', pattern: ( />/u                                     ), }\n    lexer.add_lexeme { mode, tid: 'text',           pattern: ( suffix '+', charSet.complement /[>\\\\]/u  ), }\n    lexer.add_lexeme { mode, tid: 'other',          pattern: ( /./u                                     ), }\n  #.........................................................................................................\n  probes        = [\n    \"helo <bold>`world`</bold>\"\n    \"<x v=\\\\> z=42>\"\n    \"<x v=\\\\> z=42\\\\>\"\n    \"a <b\"\n    \"what? error?\"\n    \"d <\"\n    \"<c\"\n    \"<\"\n    \"\"\n    \"helo \\\\<bold>`world`</bold>\"\n    \"<b>helo \\\\<bold>`world`</bold></b>\"\n    \"<i><b></b></i>\"\n    ]\n  #.......................................................................................................\n  for probe in probes\n    whisper '^31-1^', 'â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”'\n    tokens    = lexer.run probe\n    #.......................................................................................................\n    for token, idx in tokens\n      continue unless token.key is '$error'\n      token.key = GUY.trm.red token.key\n    H.tabulate \"tokens of #{rpr probe}\", tokens\n  #.........................................................................................................\n  return null\n\n#-----------------------------------------------------------------------------------------------------------\ndemo_paragraphs = ->\n  lexer   = new Interlex { dotall: true, }\n  #.........................................................................................................\n  mode        = 'plain'\n  lws_pattern = /// [ \\u{2000}-\\u{200a}\n                      \\u{0009}\n                      \\u{000b}-\\u{000d}\n                      \\u{0020}\n                      \\u{0085}\n                      \\u{00a0}\n                      \\u{2028}\n                      \\u{2029}\n                      \\u{202f}\n                      \\u{205f}\n                      \\u{3000} ] ///u\n  lws = lws_pattern.source\n  lexer.add_lexeme { mode, tid: 'escnl', pattern: ( /\\\\\\n/u    ), }           # newline preced by backslash\n  lexer.add_lexeme { mode, tid: 'nls',   pattern: ( ///  (?:  #{lws}*         # any linear whitespace\n                                                              (?<! \\\\ ) \\n    # newline not preceded by backslash\n                                                              #{lws}*         # any linear whitespace\n                                                          ){2,}               # two or more\n                                                              ///u ), }\n  lexer.add_lexeme { mode, tid: 'p',     pattern: /// (?: \\\\\\n | . )+?        # one or more of escaped newline or any, non-greedy\n                                                      (?= \\n #{lws}* \\n | $ ) # preceding two newlines or EOT\n                                                      ///u, }\n  #.........................................................................................................\n  probe = \"\"\"\n    first glorious\n    paragraph\n\n    \\x20\\x20\n    second slightly longer\n    paragraph\n    of text\n\n    foo\\\\\n    bar\n\n    x\\\\\n\n    y\n\n    \"\"\"\n  # lexer._finalize()\n  # info '^59-1^', lexer.registry.plain.pattern\n  # urge '^59-2^', rpr probe.replace ///#{lws}+\\n///mgu, '\\n'\n  # probe = probe.replace ///#{lws}+$///mgu, ''\n  urge '^59-3^', rpr probe\n  # re = /(?:.|(?:\\n(?!\\n)))*\\n$\\n$/muy\n  # urge '^59-3^', re.lastIndex, rpr probe.match re\n  # urge '^59-3^', re.lastIndex, rpr probe.match re\n  # urge '^59-4^', rpr probe.replace ///\\s+?$///mgu, '\\n'\n  H.tabulate \"paragraphs\", lexer.run probe\n  #.........................................................................................................\n  return null\n\n\n#-----------------------------------------------------------------------------------------------------------\ndemo_htmlish_with_paragraphs = ->\n\n\n############################################################################################################\nif module is require.main then do =>\n  # demo_1()\n  # demo_flags()\n  # demo_htmlish()\n  demo_paragraphs()\n  # res = [\n  #   /a(?<chr>.).*/u\n  #   /.*d(?<chr>.)/u\n  #   ]\n  # # re_2 = /(?<a>a(?<að”›b>.)).*(?<d>d(?<dð”›b>.))/u\n  # for re, idx in res\n  #   name = \"g#{idx + 1}\"\n  #   source = re.source.replace /(?<!\\\\)\\(\\?<([^>]+)>/gu, \"(?<#{name}ð”›$1>\"\n  #   source = \"(?<#{name}>#{source})\"\n  #   res[ idx ] = new RegExp source, re.flags\n  # debug '^45-1^', res\n  # debug '^45-1^', re = sequence res...\n  # urge { ( 'abcdef'.match re )?.groups..., }\n\n"
  ]
}