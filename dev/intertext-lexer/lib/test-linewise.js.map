{
  "version": 3,
  "file": "",
  "sourceRoot": "",
  "sources": [
    "../src/test-linewise.coffee"
  ],
  "names": [],
  "mappings": "AACA;EAAA;AAAA,MAAA,KAAA,EAAA,GAAA,EAAA,CAAA,EAAA,IAAA,EAAA,GAAA,EAAA,KAAA,EAAA,KAAA,EAAA,KAAA,EAAA,IAAA,EAAA,MAAA,EAAA,GAAA,EAAA,IAAA,EAAA,IAAA,EAAA,OAAA,EAAA,GAAA,EAAA,IAAA,EAAA,GAAA,EAAA,SAAA,EAAA,KAAA,EAAA,MAAA,EAAA,GAAA,EAAA,KAAA,EAAA,IAAA,EAAA,OAAA,EAAA,KAAA,EAAA,IAAA,EAAA,QAAA,EAAA,gBAAA,EAAA,IAAA,EAAA,OAAA;;;EAIA,GAAA,GAA4B,OAAA,CAAQ,KAAR;;EAC5B,CAAA,CAAE,KAAF,EACE,KADF,EAEE,IAFF,EAGE,IAHF,EAIE,KAJF,EAKE,MALF,EAME,IANF,EAOE,IAPF,EAQE,OARF,CAAA,GAQ4B,GAAG,CAAC,GAAG,CAAC,WAAR,CAAoB,gCAApB,CAR5B;;EASA,CAAA,CAAE,GAAF,EACE,OADF,EAEE,IAFF,EAGE,GAHF,CAAA,GAG4B,GAAG,CAAC,GAHhC,EAdA;;;EAmBA,IAAA,GAA4B,OAAA,CAAQ,wBAAR;;EAC5B,IAAA,GAA4B,OAAA,CAAQ,MAAR,EApB5B;;;EAsBA,KAAA,GAA4B,IAAI,CAAE,OAAA,CAAQ,WAAR,CAAF,CAAuB,CAAC,SAA5B,CAAA;;EAC5B,CAAA,CAAE,GAAF,EACE,MADF,EAEE,OAFF,EAGE,QAHF,EAIE,gBAJF,CAAA,GAI4B,KAAK,CAAC,MAAN,CAAA,CAJ5B;;EAKA,GAAA,GAA4B,MAAM,CAAC;;EACnC,GAAA,GAA4B,OAAA,CAAQ,mBAAR;;EAC5B,CAAA,GAA4B,OAAA,CAAQ,sBAAR;;EAC5B,KAAA,GAA4B,CAAE,GAAF,EAAO,CAAP,CAAA,GAAA;WAAe,IAAI,OAAJ,CAAY,QAAA,CAAE,OAAF,CAAA;aAAe,UAAA,CAAW,CAAE,QAAA,CAAA,CAAA;eAAG,OAAA,CAAQ,CAAA,CAAA,CAAR;MAAH,CAAF,CAAX,EAA+B,GAAA,GAAM,IAArC;IAAf,CAAZ;EAAf;;EAC5B,CAAA,CAAE,KAAF,CAAA,GAA4B,OAAA,CAAQ,qBAAR,CAA5B;;EACA,CAAA,CAAE,SAAF,EACE,IADF,EAEE,KAFF,CAAA,GAE4B,KAF5B,EAjCA;;;EAuCA,IAAC,CAAA,mCAAD,GAAuC,QAAA,CAAE,CAAF,EAAK,IAAL,CAAA;AACvC,QAAA,EAAA,EAAA,QAAA,EAAA,CAAA,EAAA,GAAA,EAAA,KAAA,EAAA,GAAA,EAAA,CAAA,EAAA,GAAA,EAAA,KAAA,EAAA,IAAA,EAAA,GAAA,EAAA,OAAA,EAAA,SAAA,EAAA,IAAA,EAAA,KAAA,EAAA,mBAAA,EAAA,GAAA,EAAA,IAAA,EAAA,MAAA,EAAA,IAAA,EAAA,KAAA,EAAA,MAAA,EAAA;IAAE,EAAA,GAAU,OAAA,CAAQ,SAAR;IACV,GAAA,GAAU,OAAA,CAAQ,mBAAR;IACV,CAAA;MAAE,QAAF;MAAY,OAAA,EAAS;IAArB,CAAA,GAA4B,OAAA,CAAQ,+BAAR,CAA5B;IACA,mBAAA,GAAsB;MACpB,CAAE,CAAE,iCAAF;MAAqC,IAArC,CAAF;MAAgF,CAAA,sHAAA,CAAhF,CADoB;MAEpB,CAAE,CAAE,yCAAF;MAA6C,IAA7C,CAAF;MAAgF,MAAhF,CAFoB;MAGpB,CAAE,CAAE,kDAAF;MAAsD,IAAtD,CAAF;MAAgF,WAAhF,CAHoB;MAIpB,CAAE,CAAE,yDAAF;MAA6D,IAA7D,CAAF;MAAgF,mBAAhF,CAJoB;MAKpB,CAAE,CAAE,2DAAF;MAA+D,IAA/D,CAAF;MAAgF,wBAAhF,CALoB;MAMpB,CAAE,CAAE,2CAAF;MAA+C,IAA/C,CAAF;MAAgF,+DAAhF,CANoB;MAOpB,CAAE,CAAE,0CAAF;MAA8C,IAA9C,CAAF;MAAgF,8EAAhF,CAPoB;MAQpB,CAAE,CAAE,8CAAF;MAAkD,IAAlD,CAAF;MAAgF,+BAAhF,CARoB;MASpB,CAAE,CAAE,uDAAF;MAA2D,IAA3D,CAAF;MAAgF,+CAAhF,CAToB;MAUpB;QAAE;UAAE,uDAAF;UAA2D;YAAE,IAAA,EAAM;UAAR,CAA3D;SAAF;QAAgF,+CAAhF;OAVoB;MAWpB;QAAE;UAAE,uDAAF;UAA2D;YAAE,IAAA,EAAM;UAAR,CAA3D;SAAF;QAAgF,iFAAhF;OAXoB;MAYpB,CAAE,CAAE,4CAAF;MAAgD,IAAhD,CAAF;MAAgF,oCAAhF,CAZoB;MAapB,CAAE,CAAE,8CAAF;MAAkD,IAAlD,CAAF;MAAgF,oCAAhF,CAboB;MAHxB;;IAmBE,SAAA,GAAY,QAAA,CAAA,CAAA;AACd,UAAA,KAAA,EAAA;MAAI,KAAA,GAAU,IAAI,QAAJ,CAAa;QAAE,QAAA,EAAU;MAAZ,CAAb,EAAd;;;MAGI,IAAA,GAAU,QAHd;;MAKI,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,IAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,MAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,OAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;AACA,aAAO;IATG,EAnBd;;IA8BE,KAAA,qDAAA;MAAI,CAAE,KAAF,EAAS,OAAT;MACF,KAAA,GAAc,SAAA,CAAA;MACd,MAAA,GAAc;MACd,MAAA,GAAc;MACd,CAAE,IAAF,EACE,GADF,CAAA,GACc;MACd,IAAA,GAAc,IAAI,CAAC,OAAL,CAAa,IAAI,CAAC,IAAL,CAAU,SAAV,EAAqB,IAArB,CAAb;MACd,IAAA,GAAc;;AAAE;AAAA;QAAA,KAAA,WAAA;uBAAA;QAAA,CAAA;;UAAF,CAAkD,CAAC,IAAnD,CAAwD,EAAxD;AAEd;;MAAA,KAAA,QAAA;SAAI,CAAE,GAAF,EAAO,IAAP,EAAa,GAAb;AACF;QAAA,KAAA,aAAA;UACE,MAAM,CAAC,IAAP,CAAY,KAAZ;UACA,KAAA,GAAQ,IAAI;;YACZ,CAAC,CAAE,EAAH,CAAM,KAAK,CAAC,KAAZ,EAAmB,KAAnB;;UACA,MAAM,CAAC,IAAP,CAAY,CAAA,CAAA,CAAG,KAAK,CAAC,GAAT,CAAA,CAAA,CAAA,CAAgB,GAAA,CAAI,KAAK,CAAC,KAAV,CAAhB,CAAA,CAAZ;QAJF;MADF,CARJ;;MAeI,MAAA,GAAS,MAAM,CAAC,IAAP,CAAY,GAAZ;MACT,KAAA,CAAM,QAAN,EAAgB,GAAA,CAAI,MAAJ,CAAhB;;QACA,CAAC,CAAE,EAAH,CAAM,MAAN,EAAc,OAAd;;IAlBF;;MAqBA;;AACA,WAAO;EArD8B,EAvCvC;;;EA+FA,IAAC,CAAA,mCAAD,GAAuC,QAAA,CAAE,CAAF,EAAK,IAAL,CAAA;AACvC,QAAA,EAAA,EAAA,QAAA,EAAA,CAAA,EAAA,GAAA,EAAA,KAAA,EAAA,CAAA,EAAA,GAAA,EAAA,KAAA,EAAA,IAAA,EAAA,OAAA,EAAA,SAAA,EAAA,IAAA,EAAA,KAAA,EAAA,mBAAA,EAAA,GAAA,EAAA,MAAA,EAAA,IAAA,EAAA,KAAA,EAAA;IAAE,EAAA,GAAU,OAAA,CAAQ,SAAR;IACV,GAAA,GAAU,OAAA,CAAQ,mBAAR;IACV,CAAA;MAAE,QAAF;MAAY,OAAA,EAAS;IAArB,CAAA,GAA4B,OAAA,CAAQ,+BAAR,CAA5B;IACA,mBAAA,GAAsB;MACpB,CAAE,CAAE,iCAAF;MAAqC,IAArC,CAAF;MAAgF,CAAA,sHAAA,CAAhF,CADoB;MAEpB,CAAE,CAAE,yCAAF;MAA6C,IAA7C,CAAF;MAAgF,MAAhF,CAFoB;MAGpB,CAAE,CAAE,kDAAF;MAAsD,IAAtD,CAAF;MAAgF,WAAhF,CAHoB;MAIpB,CAAE,CAAE,yDAAF;MAA6D,IAA7D,CAAF;MAAgF,mBAAhF,CAJoB;MAKpB,CAAE,CAAE,2DAAF;MAA+D,IAA/D,CAAF;MAAgF,wBAAhF,CALoB;MAMpB,CAAE,CAAE,2CAAF;MAA+C,IAA/C,CAAF;MAAgF,+DAAhF,CANoB;MAOpB,CAAE,CAAE,0CAAF;MAA8C,IAA9C,CAAF;MAAgF,8EAAhF,CAPoB;MAQpB,CAAE,CAAE,8CAAF;MAAkD,IAAlD,CAAF;MAAgF,+BAAhF,CARoB;MASpB,CAAE,CAAE,uDAAF;MAA2D,IAA3D,CAAF;MAAgF,+CAAhF,CAToB;MAUpB;QAAE;UAAE,uDAAF;UAA2D;YAAE,IAAA,EAAM;UAAR,CAA3D;SAAF;QAAgF,+CAAhF;OAVoB;MAWpB;QAAE;UAAE,uDAAF;UAA2D;YAAE,IAAA,EAAM;UAAR,CAA3D;SAAF;QAAgF,iFAAhF;OAXoB;MAYpB,CAAE,CAAE,4CAAF;MAAgD,IAAhD,CAAF;MAAgF,oCAAhF,CAZoB;MAapB,CAAE,CAAE,8CAAF;MAAkD,IAAlD,CAAF;MAAgF,oCAAhF,CAboB;MAHxB;;IAmBE,SAAA,GAAY,QAAA,CAAA,CAAA;AACd,UAAA,KAAA,EAAA;MAAI,KAAA,GAAU,IAAI,QAAJ,CAAa;QAAE,QAAA,EAAU;MAAZ,CAAb,EAAd;;;MAGI,IAAA,GAAU,QAHd;;MAKI,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,IAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,MAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,OAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;AACA,aAAO;IATG,EAnBd;;IA8BE,KAAA,qDAAA;MAAI,CAAE,KAAF,EAAS,OAAT;MACF,KAAA,GAAc,SAAA,CAAA;MACd,MAAA,GAAc;MACd,MAAA,GAAc;MACd,CAAE,IAAF,EACE,GADF,CAAA,GACc;MACd,IAAA,GAAc,IAAI,CAAC,OAAL,CAAa,IAAI,CAAC,IAAL,CAAU,SAAV,EAAqB,IAArB,CAAb;MACd,IAAA,GAAc;;AAAE;AAAA;QAAA,KAAA,WAAA;uBAAA;QAAA,CAAA;;UAAF,CAAkD,CAAC,IAAnD,CAAwD,EAAxD;AACd;MAAA,KAAA,YAAA,GAAA;;QAEE,MAAM,CAAC,IAAP,CAAY,KAAZ;QACA,KAAA,GAAQ,IAAI;;UACZ,CAAC,CAAE,EAAH,CAAM,KAAK,CAAC,KAAZ,EAAmB,KAAnB;;QACA,MAAM,CAAC,IAAP,CAAY,CAAA,CAAA,CAAG,KAAK,CAAC,GAAT,CAAA,CAAA,CAAA,CAAgB,GAAA,CAAI,KAAK,CAAC,KAAV,CAAhB,CAAA,CAAZ;MALF,CAPJ;;MAcI,MAAA,GAAS,MAAM,CAAC,IAAP,CAAY,GAAZ;MACT,KAAA,CAAM,QAAN,EAAgB,GAAA,CAAI,MAAJ,CAAhB;;QACA,CAAC,CAAE,EAAH,CAAM,MAAN,EAAc,OAAd;;IAjBF;;MAoBA;;AACA,WAAO;EApD8B,EA/FvC;;;EAsJA,IAAC,CAAA,mCAAD,GAAuC,QAAA,CAAE,CAAF,EAAK,IAAL,CAAA;AACvC,QAAA,EAAA,EAAA,QAAA,EAAA,CAAA,EAAA,GAAA,EAAA,KAAA,EAAA,GAAA,EAAA,CAAA,EAAA,GAAA,EAAA,KAAA,EAAA,IAAA,EAAA,OAAA,EAAA,SAAA,EAAA,IAAA,EAAA,KAAA,EAAA,mBAAA,EAAA,GAAA,EAAA,MAAA,EAAA,MAAA,EAAA,KAAA,EAAA,MAAA,EAAA;IAAE,EAAA,GAAU,OAAA,CAAQ,SAAR;IACV,GAAA,GAAU,OAAA,CAAQ,mBAAR;IACV,CAAA;MAAE,QAAF;MAAY,OAAA,EAAS;IAArB,CAAA,GAA4B,OAAA,CAAQ,+BAAR,CAA5B;IACA,mBAAA,GAAsB;MACpB,CAAE,CAAE,iCAAF;MAAqC,IAArC,CAAF;MAAgF,CAAA,sHAAA,CAAhF,CADoB;MAEpB,CAAE,CAAE,yCAAF;MAA6C,IAA7C,CAAF;MAAgF,MAAhF,CAFoB;MAGpB,CAAE,CAAE,kDAAF;MAAsD,IAAtD,CAAF;MAAgF,WAAhF,CAHoB;MAIpB,CAAE,CAAE,yDAAF;MAA6D,IAA7D,CAAF;MAAgF,mBAAhF,CAJoB;MAKpB,CAAE,CAAE,2DAAF;MAA+D,IAA/D,CAAF;MAAgF,wBAAhF,CALoB;MAMpB,CAAE,CAAE,2CAAF;MAA+C,IAA/C,CAAF;MAAgF,+DAAhF,CANoB;MAOpB,CAAE,CAAE,0CAAF;MAA8C,IAA9C,CAAF;MAAgF,8EAAhF,CAPoB;MAQpB,CAAE,CAAE,8CAAF;MAAkD,IAAlD,CAAF;MAAgF,+BAAhF,CARoB;MASpB,CAAE,CAAE,uDAAF;MAA2D,IAA3D,CAAF;MAAgF,+CAAhF,CAToB;MAUpB;QAAE;UAAE,uDAAF;UAA2D;YAAE,IAAA,EAAM;UAAR,CAA3D;SAAF;QAAgF,+CAAhF;OAVoB;MAWpB;QAAE;UAAE,uDAAF;UAA2D;YAAE,IAAA,EAAM;UAAR,CAA3D;SAAF;QAAgF,iFAAhF;OAXoB;MAYpB,CAAE,CAAE,4CAAF;MAAgD,IAAhD,CAAF;MAAgF,oCAAhF,CAZoB;MAapB,CAAE,CAAE,8CAAF;MAAkD,IAAlD,CAAF;MAAgF,oCAAhF,CAboB;MAHxB;;IAmBE,SAAA,GAAY,QAAA,CAAE,GAAF,CAAA;AACd,UAAA,KAAA,EAAA;MAAI,KAAA,GAAU,IAAI,QAAJ,CAAa;QAAE,QAAA,EAAU,IAAZ;QAAkB,GAAA;MAAlB,CAAb,EAAd;;;MAGI,IAAA,GAAU,QAHd;;MAKI,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,IAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,MAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;MACA,KAAK,CAAC,UAAN,CAAiB;QAAE,IAAF;QAAQ,GAAA,EAAK,OAAb;QAAyB,OAAA,EAAW;MAApC,CAAjB;AACA,aAAO;IATG,EAnBd;;IA8BE,KAAA,qDAAA;MAAI,CAAE,KAAF,EAAS,OAAT;MACF,MAAA,GAAkB;MAClB,MAAA,GAAkB;MAClB,CAAE,IAAF,EACE,GADF,CAAA,GACkB;MAClB,KAAA,GAAkB,SAAA,CAAU,GAAV;MAClB,IAAA,GAAkB,IAAI,CAAC,OAAL,CAAa,IAAI,CAAC,IAAL,CAAU,SAAV,EAAqB,IAArB,CAAb;MAClB,MAAA,GAAkB,EAAE,CAAC,YAAH,CAAgB,IAAhB,EAAsB;QAAE,QAAA,EAAU;MAAZ,CAAtB;MAClB,cAAA,GAAkB;;AAAE;AAAA;QAAA,KAAA,QAAA;WAAe,CAAE,IAAF,EAAQ,GAAR;uBAAf,IAAA,GAAO;QAAP,CAAA;;UAAF,CAAiF,CAAC,IAAlF,CAAuF,EAAvF;AAClB;MAAA,KAAA,YAAA,GAAA;;QAEE,IAAA,CAAK,QAAL,EAAe,KAAf;QACA,MAAM,CAAC,IAAP,CAAY,KAAZ;QACA,KAAA,GAAQ,cAAc;;UACtB,CAAC,CAAE,EAAH,CAAM,KAAK,CAAC,KAAZ,EAAmB,KAAnB;;QACA,MAAM,CAAC,IAAP,CAAY,CAAA,CAAA,CAAG,KAAK,CAAC,GAAT,CAAA,CAAA,CAAA,CAAgB,GAAA,CAAI,KAAK,CAAC,KAAV,CAAhB,CAAA,CAAZ;MANF,CARJ;;MAgBI,MAAA,GAAS,MAAM,CAAC,IAAP,CAAY,GAAZ;MACT,KAAA,CAAM,QAAN,EAAgB,GAAA,CAAI,MAAJ,CAAhB;;QACA,CAAC,CAAE,EAAH,CAAM,MAAN,EAAc,OAAd;;IAnBF;;MAsBA;;AACA,WAAO;EAtD8B,EAtJvC;;;EAgNA,IAAG,OAAO,CAAC,IAAR,KAAgB,MAAnB;IAAkC,CAAA,CAAA,CAAA,GAAA,EAAA;;aAEhC,IAAA,CAAK,IAAC,CAAA,mCAAN;IAFgC,CAAA,IAAlC;;;EAhNA;AAAA",
  "sourcesContent": [
    "\n'use strict'\n\n\n############################################################################################################\nGUY                       = require 'guy'\n{ alert\n  debug\n  help\n  info\n  plain\n  praise\n  urge\n  warn\n  whisper }               = GUY.trm.get_loggers 'INTERTEXT-LEXER/TESTS/LINEWISE'\n{ rpr\n  inspect\n  echo\n  log     }               = GUY.trm\n#...........................................................................................................\ntest                      = require '../../../apps/guy-test'\nPATH                      = require 'path'\n# FS                        = require 'fs'\ntypes                     = new ( require 'intertype' ).Intertype\n{ isa\n  equals\n  type_of\n  validate\n  validate_list_of }      = types.export()\nSQL                       = String.raw\nguy                       = require '../../../apps/guy'\nH                         = require '../../../lib/helpers'\nafter                     = ( dts, f  ) => new Promise ( resolve ) -> setTimeout ( -> resolve f() ), dts * 1000\n{ DATOM }                 = require '../../../apps/datom'\n{ new_datom\n  lets\n  stamp     }             = DATOM\n\n\n#-----------------------------------------------------------------------------------------------------------\n@GUY_str_walk_lines_with_positions_1 = ( T, done ) ->\n  FS      = require 'node:fs'\n  GUY     = require '../../../apps/guy'\n  { Interlex, compose: c, } = require '../../../apps/intertext-lexer'\n  probes_and_matchers = [\n    [ [ '../../../assets/a-few-words.txt', null ],                                  \"\"\"1:\"Ångström's\",2:'éclair',3:\"éclair's\",4:'éclairs',5:'éclat',6:\"éclat's\",7:'élan',8:\"élan's\",9:'émigré',10:\"émigré's\\\"\"\"\" ]\n    [ [ '../../../assets/datamill/empty-file.txt', null ],                          \"1:''\" ]\n    [ [ '../../../assets/datamill/file-with-single-nl.txt', null ],                 \"1:'',2:''\" ]\n    [ [ '../../../assets/datamill/file-with-3-lines-no-eofnl.txt', null ],          \"1:'1',2:'2',3:'3'\" ]\n    [ [ '../../../assets/datamill/file-with-3-lines-with-eofnl.txt', null ],        \"1:'1',2:'2',3:'3',4:''\" ]\n    [ [ '../../../assets/datamill/windows-crlf.txt', null ],                        \"1:'this',2:'file',3:'written',4:'on',5:'MS',5:' ',5:'Notepad'\" ]\n    [ [ '../../../assets/datamill/mixed-usage.txt', null ],                         \"1:'all',2:'𠀀bases',3:'',4:'are',4:' ',4:'belong',5:'𠀀to',5:' ',5:'us',6:''\" ]\n    [ [ '../../../assets/datamill/all-empty-mixed.txt', null ],                     \"1:'',2:'',3:'',4:'',5:'',6:''\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', null ],            \"1:'line',2:'with',3:'trailing',4:'whitespace'\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', { trim: true } ],  \"1:'line',2:'with',3:'trailing',4:'whitespace'\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', { trim: false } ], \"1:'line',1:'   ',2:'with',2:'   ',3:'trailing',3:'\\\\t\\\\t',4:'whitespace',4:'　 '\" ]\n    [ [ '../../../assets/datamill/lines-with-lf.txt', null ],                       \"1:'line1',2:'line2',3:'line3',4:''\" ]\n    [ [ '../../../assets/datamill/lines-with-crlf.txt', null ],                     \"1:'line1',2:'line2',3:'line3',4:''\" ]\n    ]\n  #.........................................................................................................\n  new_lexer = ->\n    lexer   = new Interlex { linewise: true, }\n    # T?.eq lexer.cfg.linewise, true\n    # T?.eq lexer.state.lnr, 0\n    mode    = 'plain'\n    # lexer.add_lexeme { mode, tid: 'eol',      pattern: ( /$/u  ), }\n    lexer.add_lexeme { mode, tid: 'ws',       pattern: ( /\\s+/u ), }\n    lexer.add_lexeme { mode, tid: 'word',     pattern: ( /\\S+/u ), }\n    lexer.add_lexeme { mode, tid: 'empty',    pattern: ( /^$/u ), }\n    return lexer\n  #.........................................................................................................\n  for [ probe, matcher, ] in probes_and_matchers\n    lexer       = new_lexer()\n    result      = []\n    tokens      = []\n    [ path\n      cfg ]     = probe\n    path        = PATH.resolve PATH.join __dirname, path\n    text        = ( line for line from GUY.fs.walk_lines path, cfg ).join ''\n    # debug '^23-4^', rpr text\n    for { lnr, line, eol, } from GUY.fs.walk_lines_with_positions path, cfg\n      for token from lexer.walk line\n        tokens.push token\n        chunk = text[ token.start ... token.stop ]\n        T?.eq token.value, chunk\n        result.push \"#{token.lnr}:#{rpr token.value}\"\n    #.........................................................................................................\n    result = result.join ','\n    debug '^23-5^', rpr result\n    T?.eq result, matcher\n    # H.tabulate ( rpr probe ), tokens\n  #.........................................................................................................\n  done?()\n  return null\n\n#-----------------------------------------------------------------------------------------------------------\n@GUY_str_walk_lines_with_positions_2 = ( T, done ) ->\n  FS      = require 'node:fs'\n  GUY     = require '../../../apps/guy'\n  { Interlex, compose: c, } = require '../../../apps/intertext-lexer'\n  probes_and_matchers = [\n    [ [ '../../../assets/a-few-words.txt', null ],                                  \"\"\"1:\"Ångström's\",2:'éclair',3:\"éclair's\",4:'éclairs',5:'éclat',6:\"éclat's\",7:'élan',8:\"élan's\",9:'émigré',10:\"émigré's\\\"\"\"\" ]\n    [ [ '../../../assets/datamill/empty-file.txt', null ],                          \"1:''\" ]\n    [ [ '../../../assets/datamill/file-with-single-nl.txt', null ],                 \"1:'',2:''\" ]\n    [ [ '../../../assets/datamill/file-with-3-lines-no-eofnl.txt', null ],          \"1:'1',2:'2',3:'3'\" ]\n    [ [ '../../../assets/datamill/file-with-3-lines-with-eofnl.txt', null ],        \"1:'1',2:'2',3:'3',4:''\" ]\n    [ [ '../../../assets/datamill/windows-crlf.txt', null ],                        \"1:'this',2:'file',3:'written',4:'on',5:'MS',5:' ',5:'Notepad'\" ]\n    [ [ '../../../assets/datamill/mixed-usage.txt', null ],                         \"1:'all',2:'𠀀bases',3:'',4:'are',4:' ',4:'belong',5:'𠀀to',5:' ',5:'us',6:''\" ]\n    [ [ '../../../assets/datamill/all-empty-mixed.txt', null ],                     \"1:'',2:'',3:'',4:'',5:'',6:''\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', null ],            \"1:'line',2:'with',3:'trailing',4:'whitespace'\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', { trim: true } ],  \"1:'line',2:'with',3:'trailing',4:'whitespace'\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', { trim: false } ], \"1:'line',1:'   ',2:'with',2:'   ',3:'trailing',3:'\\\\t\\\\t',4:'whitespace',4:'　 '\" ]\n    [ [ '../../../assets/datamill/lines-with-lf.txt', null ],                       \"1:'line1',2:'line2',3:'line3',4:''\" ]\n    [ [ '../../../assets/datamill/lines-with-crlf.txt', null ],                     \"1:'line1',2:'line2',3:'line3',4:''\" ]\n    ]\n  #.........................................................................................................\n  new_lexer = ->\n    lexer   = new Interlex { linewise: true, }\n    # T?.eq lexer.cfg.linewise, true\n    # T?.eq lexer.state.lnr, 0\n    mode    = 'plain'\n    # lexer.add_lexeme { mode, tid: 'eol',      pattern: ( /$/u  ), }\n    lexer.add_lexeme { mode, tid: 'ws',       pattern: ( /\\s+/u ), }\n    lexer.add_lexeme { mode, tid: 'word',     pattern: ( /\\S+/u ), }\n    lexer.add_lexeme { mode, tid: 'empty',    pattern: ( /^$/u ), }\n    return lexer\n  #.........................................................................................................\n  for [ probe, matcher, ] in probes_and_matchers\n    lexer       = new_lexer()\n    result      = []\n    tokens      = []\n    [ path\n      cfg ]     = probe\n    path        = PATH.resolve PATH.join __dirname, path\n    text        = ( line for line from GUY.fs.walk_lines path, cfg ).join ''\n    for token from lexer.walk { path, cfg..., }\n      # debug '^23-4^', token\n      tokens.push token\n      chunk = text[ token.start ... token.stop ]\n      T?.eq token.value, chunk\n      result.push \"#{token.lnr}:#{rpr token.value}\"\n    #.........................................................................................................\n    result = result.join ','\n    debug '^23-4^', rpr result\n    T?.eq result, matcher\n    # H.tabulate ( rpr probe ), tokens\n  #.........................................................................................................\n  done?()\n  return null\n\n#-----------------------------------------------------------------------------------------------------------\n@GUY_str_walk_lines_with_positions_3 = ( T, done ) ->\n  FS      = require 'node:fs'\n  GUY     = require '../../../apps/guy'\n  { Interlex, compose: c, } = require '../../../apps/intertext-lexer'\n  probes_and_matchers = [\n    [ [ '../../../assets/a-few-words.txt', null ],                                  \"\"\"1:\"Ångström's\",2:'éclair',3:\"éclair's\",4:'éclairs',5:'éclat',6:\"éclat's\",7:'élan',8:\"élan's\",9:'émigré',10:\"émigré's\\\"\"\"\" ]\n    [ [ '../../../assets/datamill/empty-file.txt', null ],                          \"1:''\" ]\n    [ [ '../../../assets/datamill/file-with-single-nl.txt', null ],                 \"1:'',2:''\" ]\n    [ [ '../../../assets/datamill/file-with-3-lines-no-eofnl.txt', null ],          \"1:'1',2:'2',3:'3'\" ]\n    [ [ '../../../assets/datamill/file-with-3-lines-with-eofnl.txt', null ],        \"1:'1',2:'2',3:'3',4:''\" ]\n    [ [ '../../../assets/datamill/windows-crlf.txt', null ],                        \"1:'this',2:'file',3:'written',4:'on',5:'MS',5:' ',5:'Notepad'\" ]\n    [ [ '../../../assets/datamill/mixed-usage.txt', null ],                         \"1:'all',2:'𠀀bases',3:'',4:'are',4:' ',4:'belong',5:'𠀀to',5:' ',5:'us',6:''\" ]\n    [ [ '../../../assets/datamill/all-empty-mixed.txt', null ],                     \"1:'',2:'',3:'',4:'',5:'',6:''\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', null ],            \"1:'line',2:'with',3:'trailing',4:'whitespace'\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', { trim: true } ],  \"1:'line',2:'with',3:'trailing',4:'whitespace'\" ]\n    [ [ '../../../assets/datamill/lines-with-trailing-spcs.txt', { trim: false } ], \"1:'line',1:'   ',2:'with',2:'   ',3:'trailing',3:'\\\\t\\\\t',4:'whitespace',4:'　 '\" ]\n    [ [ '../../../assets/datamill/lines-with-lf.txt', null ],                       \"1:'line1',2:'line2',3:'line3',4:''\" ]\n    [ [ '../../../assets/datamill/lines-with-crlf.txt', null ],                     \"1:'line1',2:'line2',3:'line3',4:''\" ]\n    ]\n  #.........................................................................................................\n  new_lexer = ( cfg ) ->\n    lexer   = new Interlex { linewise: true, cfg..., }\n    # T?.eq lexer.cfg.linewise, true\n    # T?.eq lexer.state.lnr, 0\n    mode    = 'plain'\n    # lexer.add_lexeme { mode, tid: 'eol',      pattern: ( /$/u  ), }\n    lexer.add_lexeme { mode, tid: 'ws',       pattern: ( /\\s+/u ), }\n    lexer.add_lexeme { mode, tid: 'word',     pattern: ( /\\S+/u ), }\n    lexer.add_lexeme { mode, tid: 'empty',    pattern: ( /^$/u ), }\n    return lexer\n  #.........................................................................................................\n  for [ probe, matcher, ] in probes_and_matchers\n    result          = []\n    tokens          = []\n    [ path\n      cfg ]         = probe\n    lexer           = new_lexer cfg\n    path            = PATH.resolve PATH.join __dirname, path\n    source          = FS.readFileSync path, { encoding: 'utf-8', }\n    trimmed_source  = ( line + eol for { line, eol, } from GUY.fs.walk_lines_with_positions path, cfg ).join ''\n    for token from lexer.walk { source, }\n      # info '^23-4^', lexer.state\n      info '^23-4^', token\n      tokens.push token\n      chunk = trimmed_source[ token.start ... token.stop ]\n      T?.eq token.value, chunk\n      result.push \"#{token.lnr}:#{rpr token.value}\"\n    #.........................................................................................................\n    result = result.join ','\n    debug '^23-4^', rpr result\n    T?.eq result, matcher\n    # H.tabulate ( rpr probe ), tokens\n  #.........................................................................................................\n  done?()\n  return null\n\n\n############################################################################################################\nif require.main is module then do =>\n  # test @GUY_str_walk_lines_with_positions_2\n  test @GUY_str_walk_lines_with_positions_3\n  # test @\n"
  ]
}